{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivioXie/ICSI435_Group/blob/main/GAN_proto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "76Apr5GWQmgr",
        "outputId": "93bb7cae-7ab9-4cb3-b3c2-eb70511d06be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Generator Loss: 0.6782510876655579, Discriminator Loss: 0.758951723575592\n",
            "Epoch 2, Generator Loss: 0.6953996419906616, Discriminator Loss: 0.7147318720817566\n",
            "Epoch 3, Generator Loss: 0.7288620471954346, Discriminator Loss: 0.6751790642738342\n",
            "Epoch 4, Generator Loss: 0.7713083028793335, Discriminator Loss: 0.6343433856964111\n",
            "Epoch 5, Generator Loss: 0.8304993510246277, Discriminator Loss: 0.58482825756073\n",
            "Epoch 6, Generator Loss: 0.8956140279769897, Discriminator Loss: 0.5362966060638428\n",
            "Epoch 7, Generator Loss: 0.9717088937759399, Discriminator Loss: 0.4859165847301483\n",
            "Epoch 8, Generator Loss: 1.0704339742660522, Discriminator Loss: 0.4292868375778198\n",
            "Epoch 9, Generator Loss: 1.2065505981445312, Discriminator Loss: 0.36358824372291565\n",
            "Epoch 10, Generator Loss: 1.3834025859832764, Discriminator Loss: 0.2949753701686859\n",
            "Epoch 11, Generator Loss: 1.5786333084106445, Discriminator Loss: 0.23611003160476685\n",
            "Epoch 12, Generator Loss: 1.7964228391647339, Discriminator Loss: 0.18556031584739685\n",
            "Epoch 13, Generator Loss: 2.0269713401794434, Discriminator Loss: 0.1446162611246109\n",
            "Epoch 14, Generator Loss: 2.250641345977783, Discriminator Loss: 0.11396415531635284\n",
            "Epoch 15, Generator Loss: 2.4763922691345215, Discriminator Loss: 0.08983256667852402\n",
            "Epoch 16, Generator Loss: 2.693213939666748, Discriminator Loss: 0.07160834223031998\n",
            "Epoch 17, Generator Loss: 2.9003615379333496, Discriminator Loss: 0.05777888372540474\n",
            "Epoch 18, Generator Loss: 3.091034412384033, Discriminator Loss: 0.04753127321600914\n",
            "Epoch 19, Generator Loss: 3.2737159729003906, Discriminator Loss: 0.039447180926799774\n",
            "Epoch 20, Generator Loss: 3.449284076690674, Discriminator Loss: 0.03298820182681084\n",
            "Epoch 21, Generator Loss: 3.607205390930176, Discriminator Loss: 0.028082676231861115\n",
            "Epoch 22, Generator Loss: 3.752460241317749, Discriminator Loss: 0.024241868406534195\n",
            "Epoch 23, Generator Loss: 3.904082775115967, Discriminator Loss: 0.02081495150923729\n",
            "Epoch 24, Generator Loss: 4.0373616218566895, Discriminator Loss: 0.018213311210274696\n",
            "Epoch 25, Generator Loss: 4.176853656768799, Discriminator Loss: 0.015840526670217514\n",
            "Epoch 26, Generator Loss: 4.300632476806641, Discriminator Loss: 0.013991602696478367\n",
            "Epoch 27, Generator Loss: 4.395783424377441, Discriminator Loss: 0.012712424620985985\n",
            "Epoch 28, Generator Loss: 4.496502876281738, Discriminator Loss: 0.01149464026093483\n",
            "Epoch 29, Generator Loss: 4.596396446228027, Discriminator Loss: 0.010414453223347664\n",
            "Epoch 30, Generator Loss: 4.714337348937988, Discriminator Loss: 0.009261548519134521\n",
            "Epoch 31, Generator Loss: 4.801363945007324, Discriminator Loss: 0.008481184020638466\n",
            "Epoch 32, Generator Loss: 4.904778957366943, Discriminator Loss: 0.007636694703251123\n",
            "Epoch 33, Generator Loss: 5.003271102905273, Discriminator Loss: 0.006907342933118343\n",
            "Epoch 34, Generator Loss: 5.107285499572754, Discriminator Loss: 0.006216499954462051\n",
            "Epoch 35, Generator Loss: 5.188139915466309, Discriminator Loss: 0.0057273139245808125\n",
            "Epoch 36, Generator Loss: 5.269650459289551, Discriminator Loss: 0.0052741821855306625\n",
            "Epoch 37, Generator Loss: 5.348520755767822, Discriminator Loss: 0.00487192627042532\n",
            "Epoch 38, Generator Loss: 5.416782379150391, Discriminator Loss: 0.004553487524390221\n",
            "Epoch 39, Generator Loss: 5.49061393737793, Discriminator Loss: 0.004228466656059027\n",
            "Epoch 40, Generator Loss: 5.522648334503174, Discriminator Loss: 0.004101600032299757\n",
            "Epoch 41, Generator Loss: 5.580506324768066, Discriminator Loss: 0.003871399676427245\n",
            "Epoch 42, Generator Loss: 5.6713080406188965, Discriminator Loss: 0.003538683522492647\n",
            "Epoch 43, Generator Loss: 5.7267985343933105, Discriminator Loss: 0.0033501069992780685\n",
            "Epoch 44, Generator Loss: 5.816888332366943, Discriminator Loss: 0.003065824741497636\n",
            "Epoch 45, Generator Loss: 5.883928298950195, Discriminator Loss: 0.0028685987927019596\n",
            "Epoch 46, Generator Loss: 5.953871250152588, Discriminator Loss: 0.002676148898899555\n",
            "Epoch 47, Generator Loss: 6.017021179199219, Discriminator Loss: 0.002512969309464097\n",
            "Epoch 48, Generator Loss: 6.079092979431152, Discriminator Loss: 0.0023610182106494904\n",
            "Epoch 49, Generator Loss: 6.119231224060059, Discriminator Loss: 0.00226674135774374\n",
            "Epoch 50, Generator Loss: 6.182401180267334, Discriminator Loss: 0.002126372419297695\n",
            "Epoch 51, Generator Loss: 6.225608825683594, Discriminator Loss: 0.0020349069964140654\n",
            "Epoch 52, Generator Loss: 6.293442249298096, Discriminator Loss: 0.0019008381059393287\n",
            "Epoch 53, Generator Loss: 6.336574554443359, Discriminator Loss: 0.0018191200215369463\n",
            "Epoch 54, Generator Loss: 6.393357276916504, Discriminator Loss: 0.001717720995657146\n",
            "Epoch 55, Generator Loss: 6.4354400634765625, Discriminator Loss: 0.0016459437320008874\n",
            "Epoch 56, Generator Loss: 6.476934432983398, Discriminator Loss: 0.0015780561370775104\n",
            "Epoch 57, Generator Loss: 6.508452415466309, Discriminator Loss: 0.0015328453155234456\n",
            "Epoch 58, Generator Loss: 6.548063278198242, Discriminator Loss: 0.0014743773499503732\n",
            "Epoch 59, Generator Loss: 6.584624767303467, Discriminator Loss: 0.0014226323692128062\n",
            "Epoch 60, Generator Loss: 6.639491081237793, Discriminator Loss: 0.0013463248033076525\n",
            "Epoch 61, Generator Loss: 6.673815727233887, Discriminator Loss: 0.0013019513571634889\n",
            "Epoch 62, Generator Loss: 6.741230010986328, Discriminator Loss: 0.0012180801713839173\n",
            "Epoch 63, Generator Loss: 6.7994794845581055, Discriminator Loss: 0.0011497862869873643\n",
            "Epoch 64, Generator Loss: 6.841175079345703, Discriminator Loss: 0.0011028910521417856\n",
            "Epoch 65, Generator Loss: 6.890359401702881, Discriminator Loss: 0.0010499708587303758\n",
            "Epoch 66, Generator Loss: 6.926104545593262, Discriminator Loss: 0.0010131212184205651\n",
            "Epoch 67, Generator Loss: 6.972631454467773, Discriminator Loss: 0.0009673313470557332\n",
            "Epoch 68, Generator Loss: 7.008798599243164, Discriminator Loss: 0.0009330250904895365\n",
            "Epoch 69, Generator Loss: 7.049646377563477, Discriminator Loss: 0.0008953956421464682\n",
            "Epoch 70, Generator Loss: 7.090986728668213, Discriminator Loss: 0.0008593590464442968\n",
            "Epoch 71, Generator Loss: 7.131112575531006, Discriminator Loss: 0.0008256084402091801\n",
            "Epoch 72, Generator Loss: 7.165142059326172, Discriminator Loss: 0.0007979838992469013\n",
            "Epoch 73, Generator Loss: 7.214641571044922, Discriminator Loss: 0.0007600217359140515\n",
            "Epoch 74, Generator Loss: 7.248111248016357, Discriminator Loss: 0.0007350475643761456\n",
            "Epoch 75, Generator Loss: 7.284398555755615, Discriminator Loss: 0.0007091620354913175\n",
            "Epoch 76, Generator Loss: 7.33574104309082, Discriminator Loss: 0.0006742618279531598\n",
            "Epoch 77, Generator Loss: 7.354028224945068, Discriminator Loss: 0.0006619748892262578\n",
            "Epoch 78, Generator Loss: 7.390405654907227, Discriminator Loss: 0.0006387366447597742\n",
            "Epoch 79, Generator Loss: 7.4335036277771, Discriminator Loss: 0.0006120310281403363\n",
            "Epoch 80, Generator Loss: 7.460464000701904, Discriminator Loss: 0.0005961369606666267\n",
            "Epoch 81, Generator Loss: 7.486074447631836, Discriminator Loss: 0.0005807548295706511\n",
            "Epoch 82, Generator Loss: 7.497061252593994, Discriminator Loss: 0.0005750927957706153\n",
            "Epoch 83, Generator Loss: 7.519044876098633, Discriminator Loss: 0.0005633869441226125\n",
            "Epoch 84, Generator Loss: 7.533843994140625, Discriminator Loss: 0.0005542251747101545\n",
            "Epoch 85, Generator Loss: 7.5952606201171875, Discriminator Loss: 0.000521456531714648\n",
            "Epoch 86, Generator Loss: 7.596060752868652, Discriminator Loss: 0.0005203570472076535\n",
            "Epoch 87, Generator Loss: 7.653032302856445, Discriminator Loss: 0.0004914142773486674\n",
            "Epoch 88, Generator Loss: 7.7043890953063965, Discriminator Loss: 0.0004674481460824609\n",
            "Epoch 89, Generator Loss: 7.7246599197387695, Discriminator Loss: 0.00045698523172177374\n",
            "Epoch 90, Generator Loss: 7.776801109313965, Discriminator Loss: 0.0004338071448728442\n",
            "Epoch 91, Generator Loss: 7.807524681091309, Discriminator Loss: 0.00042034804937429726\n",
            "Epoch 92, Generator Loss: 7.854917526245117, Discriminator Loss: 0.0004008314572274685\n",
            "Epoch 93, Generator Loss: 7.884282112121582, Discriminator Loss: 0.0003889015642926097\n",
            "Epoch 94, Generator Loss: 7.924830913543701, Discriminator Loss: 0.00037333674845285714\n",
            "Epoch 95, Generator Loss: 7.954318523406982, Discriminator Loss: 0.00036228488897904754\n",
            "Epoch 96, Generator Loss: 7.993558406829834, Discriminator Loss: 0.0003483564069028944\n",
            "Epoch 97, Generator Loss: 8.0238037109375, Discriminator Loss: 0.00033786348649300635\n",
            "Epoch 98, Generator Loss: 8.054924011230469, Discriminator Loss: 0.00032739073503762484\n",
            "Epoch 99, Generator Loss: 8.089241027832031, Discriminator Loss: 0.0003164160589221865\n",
            "Epoch 100, Generator Loss: 8.113861083984375, Discriminator Loss: 0.0003087152726948261\n",
            "Generated Puzzle:\n",
            "[[3.7072040e-03 4.0627057e-07 4.1904438e-02]\n",
            " [1.6945368e-02 1.9574589e-04 2.9602503e-02]\n",
            " [3.3580246e-03 2.4345769e-02 8.7994057e-01]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101, Generator Loss: 8.133129119873047, Discriminator Loss: 0.00030260757193900645\n",
            "Epoch 102, Generator Loss: 8.17160415649414, Discriminator Loss: 0.000291215896140784\n",
            "Epoch 103, Generator Loss: 8.192831039428711, Discriminator Loss: 0.0002851090976037085\n",
            "Epoch 104, Generator Loss: 8.208566665649414, Discriminator Loss: 0.00028037730953656137\n",
            "Epoch 105, Generator Loss: 8.242059707641602, Discriminator Loss: 0.00027118847356177866\n",
            "Epoch 106, Generator Loss: 8.260122299194336, Discriminator Loss: 0.00026605118182487786\n",
            "Epoch 107, Generator Loss: 8.293367385864258, Discriminator Loss: 0.0002576175902504474\n",
            "Epoch 108, Generator Loss: 8.32768440246582, Discriminator Loss: 0.0002488491008989513\n",
            "Epoch 109, Generator Loss: 8.368842124938965, Discriminator Loss: 0.00023904911358840764\n",
            "Epoch 110, Generator Loss: 8.386055946350098, Discriminator Loss: 0.00023493559274356812\n",
            "Epoch 111, Generator Loss: 8.403392791748047, Discriminator Loss: 0.00023080936807673424\n",
            "Epoch 112, Generator Loss: 8.449576377868652, Discriminator Loss: 0.00022062539937905967\n",
            "Epoch 113, Generator Loss: 8.468116760253906, Discriminator Loss: 0.0002165117475669831\n",
            "Epoch 114, Generator Loss: 8.498821258544922, Discriminator Loss: 0.0002099025878123939\n",
            "Epoch 115, Generator Loss: 8.518543243408203, Discriminator Loss: 0.00020578793191816658\n",
            "Epoch 116, Generator Loss: 8.546646118164062, Discriminator Loss: 0.00019997097842860967\n",
            "Epoch 117, Generator Loss: 8.568657875061035, Discriminator Loss: 0.0001955485058715567\n",
            "Epoch 118, Generator Loss: 8.591740608215332, Discriminator Loss: 0.00019110615539830178\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d3eb9328141e>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mpuzzle_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuzzle_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuzzle_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-d3eb9328141e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpuzzle_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuzzle_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Print progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Constants\n",
        "PUZZLE_SIZE = 3  # 3x3 puzzle\n",
        "SEED_SIZE = 100\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Generate random 3x3 sliding puzzle configurations\n",
        "def generate_puzzle_batch(batch_size):\n",
        "    puzzles = []\n",
        "    for _ in range(batch_size):\n",
        "        puzzle = np.arange(PUZZLE_SIZE * PUZZLE_SIZE)\n",
        "        np.random.shuffle(puzzle)\n",
        "        puzzle = puzzle.reshape((PUZZLE_SIZE, PUZZLE_SIZE))\n",
        "        puzzles.append(puzzle)\n",
        "    return np.array(puzzles)\n",
        "\n",
        "# Generator\n",
        "def build_generator(seed_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=seed_size))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(PUZZLE_SIZE * PUZZLE_SIZE, activation='softmax'))\n",
        "    model.add(Reshape((PUZZLE_SIZE, PUZZLE_SIZE)))\n",
        "    return model\n",
        "\n",
        "# Discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(PUZZLE_SIZE, PUZZLE_SIZE)))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(64))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Build models\n",
        "generator = build_generator(SEED_SIZE)\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "\n",
        "# Training step\n",
        "@tf.function\n",
        "def train_step(puzzles):\n",
        "    noise = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_puzzles = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(puzzles, training=True)\n",
        "        fake_output = discriminator(generated_puzzles, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for puzzle_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(puzzle_batch)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch + 1}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n",
        "\n",
        "        # Generate and save a sample puzzle\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            sample_puzzle(generator)\n",
        "\n",
        "# Function to sample a generated puzzle and plot\n",
        "# Function to sample a generated puzzle and plot with labels\n",
        "# Function to sample a generated puzzle and plot with labels\n",
        "def sample_puzzle(generator_model):\n",
        "    noise = tf.random.normal([1, SEED_SIZE])\n",
        "    generated_puzzle = generator_model(noise, training=False).numpy().reshape((PUZZLE_SIZE, PUZZLE_SIZE))\n",
        "\n",
        "    print(\"Generated Puzzle:\")\n",
        "    print(generated_puzzle)\n",
        "\n",
        "    # Plot with labels\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    for i in range(PUZZLE_SIZE):\n",
        "        for j in range(PUZZLE_SIZE):\n",
        "            num = int(generated_puzzle[i, j])  # Convert to int to display as a number\n",
        "            color = 'lightblue' if num != 0 else 'white'  # Set color for blank space (0)\n",
        "            ax.add_patch(plt.Rectangle((j, PUZZLE_SIZE-i-1), 1, 1, facecolor=color, edgecolor='black'))\n",
        "\n",
        "            if num != 0:  # Only add number to non-zero cells\n",
        "                ax.text(j + 0.5, PUZZLE_SIZE-i-0.5, str(num), color='black', ha='center', va='center', fontsize=20)\n",
        "\n",
        "    ax.set_xlim(0, PUZZLE_SIZE)\n",
        "    ax.set_ylim(0, PUZZLE_SIZE)\n",
        "    ax.set_xticks(np.arange(0, PUZZLE_SIZE, 1))\n",
        "    ax.set_yticks(np.arange(0, PUZZLE_SIZE, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_aspect('equal')\n",
        "    plt.gca().invert_yaxis()  # To match typical 2D array coordinates where the origin is top-left\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Generate dataset and train\n",
        "puzzle_data = generate_puzzle_batch(1000)\n",
        "puzzle_dataset = tf.data.Dataset.from_tensor_slices(puzzle_data).batch(BATCH_SIZE)\n",
        "\n",
        "train(puzzle_dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qoV7fs-jc00h"
      }
    }
  ]
}