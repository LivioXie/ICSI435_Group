{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivioXie/ICSI435_Group/blob/main/GAN_proto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "76Apr5GWQmgr",
        "outputId": "f8e9ad3f-bce6-4dc0-be27-13bf58939e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Generator Loss: 0.6682760119438171, Discriminator Loss: 0.7595512270927429\n",
            "Epoch 2, Generator Loss: 0.6939330101013184, Discriminator Loss: 0.7123901844024658\n",
            "Epoch 3, Generator Loss: 0.7252665758132935, Discriminator Loss: 0.6770473718643188\n",
            "Epoch 4, Generator Loss: 0.7761558890342712, Discriminator Loss: 0.6296278834342957\n",
            "Epoch 5, Generator Loss: 0.836067795753479, Discriminator Loss: 0.5805301666259766\n",
            "Epoch 6, Generator Loss: 0.9056620597839355, Discriminator Loss: 0.5300789475440979\n",
            "Epoch 7, Generator Loss: 0.9908950924873352, Discriminator Loss: 0.4747239351272583\n",
            "Epoch 8, Generator Loss: 1.106212854385376, Discriminator Loss: 0.4104393422603607\n",
            "Epoch 9, Generator Loss: 1.2512696981430054, Discriminator Loss: 0.3442615866661072\n",
            "Epoch 10, Generator Loss: 1.4259331226348877, Discriminator Loss: 0.28110212087631226\n",
            "Epoch 11, Generator Loss: 1.6313765048980713, Discriminator Loss: 0.22327832877635956\n",
            "Epoch 12, Generator Loss: 1.8518918752670288, Discriminator Loss: 0.17523275315761566\n",
            "Epoch 13, Generator Loss: 2.0772299766540527, Discriminator Loss: 0.13739079236984253\n",
            "Epoch 14, Generator Loss: 2.3057563304901123, Discriminator Loss: 0.10773451626300812\n",
            "Epoch 15, Generator Loss: 2.531308650970459, Discriminator Loss: 0.08509310334920883\n",
            "Epoch 16, Generator Loss: 2.741865396499634, Discriminator Loss: 0.06842076778411865\n",
            "Epoch 17, Generator Loss: 2.9394774436950684, Discriminator Loss: 0.05581323429942131\n",
            "Epoch 18, Generator Loss: 3.1252360343933105, Discriminator Loss: 0.046118732541799545\n",
            "Epoch 19, Generator Loss: 3.2886741161346436, Discriminator Loss: 0.03904305025935173\n",
            "Epoch 20, Generator Loss: 3.4664106369018555, Discriminator Loss: 0.03258523344993591\n",
            "Epoch 21, Generator Loss: 3.6346874237060547, Discriminator Loss: 0.027471553534269333\n",
            "Epoch 22, Generator Loss: 3.7788124084472656, Discriminator Loss: 0.023765288293361664\n",
            "Epoch 23, Generator Loss: 3.9085888862609863, Discriminator Loss: 0.02084171772003174\n",
            "Epoch 24, Generator Loss: 4.04438591003418, Discriminator Loss: 0.01816703751683235\n",
            "Epoch 25, Generator Loss: 4.1718363761901855, Discriminator Loss: 0.015985706821084023\n",
            "Epoch 26, Generator Loss: 4.294309139251709, Discriminator Loss: 0.014133465476334095\n",
            "Epoch 27, Generator Loss: 4.397322654724121, Discriminator Loss: 0.012731361202895641\n",
            "Epoch 28, Generator Loss: 4.515848159790039, Discriminator Loss: 0.011297982186079025\n",
            "Epoch 29, Generator Loss: 4.615833282470703, Discriminator Loss: 0.010211017914116383\n",
            "Epoch 30, Generator Loss: 4.712697982788086, Discriminator Loss: 0.009258895181119442\n",
            "Epoch 31, Generator Loss: 4.802471160888672, Discriminator Loss: 0.00845875684171915\n",
            "Epoch 32, Generator Loss: 4.902077674865723, Discriminator Loss: 0.007654259912669659\n",
            "Epoch 33, Generator Loss: 4.986847877502441, Discriminator Loss: 0.007024738471955061\n",
            "Epoch 34, Generator Loss: 5.067802429199219, Discriminator Loss: 0.0064729247242212296\n",
            "Epoch 35, Generator Loss: 5.147936820983887, Discriminator Loss: 0.0059658498503267765\n",
            "Epoch 36, Generator Loss: 5.225645065307617, Discriminator Loss: 0.005515872035175562\n",
            "Epoch 37, Generator Loss: 5.294383525848389, Discriminator Loss: 0.0051469882018864155\n",
            "Epoch 38, Generator Loss: 5.387622833251953, Discriminator Loss: 0.004689517430961132\n",
            "Epoch 39, Generator Loss: 5.458780288696289, Discriminator Loss: 0.0043646846897900105\n",
            "Epoch 40, Generator Loss: 5.525843620300293, Discriminator Loss: 0.00408095633611083\n",
            "Epoch 41, Generator Loss: 5.589491844177246, Discriminator Loss: 0.0038277325220406055\n",
            "Epoch 42, Generator Loss: 5.664422035217285, Discriminator Loss: 0.0035522894468158484\n",
            "Epoch 43, Generator Loss: 5.724693298339844, Discriminator Loss: 0.003344879951328039\n",
            "Epoch 44, Generator Loss: 5.78184700012207, Discriminator Loss: 0.0031582999508827925\n",
            "Epoch 45, Generator Loss: 5.848282337188721, Discriminator Loss: 0.0029571866616606712\n",
            "Epoch 46, Generator Loss: 5.904674053192139, Discriminator Loss: 0.0027942124288529158\n",
            "Epoch 47, Generator Loss: 5.966513633728027, Discriminator Loss: 0.002626148983836174\n",
            "Epoch 48, Generator Loss: 6.019251823425293, Discriminator Loss: 0.0024902939330786467\n",
            "Epoch 49, Generator Loss: 6.077625274658203, Discriminator Loss: 0.002348559908568859\n",
            "Epoch 50, Generator Loss: 6.125946998596191, Discriminator Loss: 0.0022356275003403425\n",
            "Epoch 51, Generator Loss: 6.180569171905518, Discriminator Loss: 0.0021160184405744076\n",
            "Epoch 52, Generator Loss: 6.239411354064941, Discriminator Loss: 0.0019945092499256134\n",
            "Epoch 53, Generator Loss: 6.2897114753723145, Discriminator Loss: 0.0018953417893499136\n",
            "Epoch 54, Generator Loss: 6.343459129333496, Discriminator Loss: 0.0017957502277567983\n",
            "Epoch 55, Generator Loss: 6.389153957366943, Discriminator Loss: 0.001714803627692163\n",
            "Epoch 56, Generator Loss: 6.4369707107543945, Discriminator Loss: 0.0016343514434993267\n",
            "Epoch 57, Generator Loss: 6.480929851531982, Discriminator Loss: 0.0015632816357538104\n",
            "Epoch 58, Generator Loss: 6.534256935119629, Discriminator Loss: 0.0014821726363152266\n",
            "Epoch 59, Generator Loss: 6.583103656768799, Discriminator Loss: 0.0014113913057371974\n",
            "Epoch 60, Generator Loss: 6.618332862854004, Discriminator Loss: 0.0013618188677355647\n",
            "Epoch 61, Generator Loss: 6.667313098907471, Discriminator Loss: 0.0012967530637979507\n",
            "Epoch 62, Generator Loss: 6.711935043334961, Discriminator Loss: 0.0012401489075273275\n",
            "Epoch 63, Generator Loss: 6.759777069091797, Discriminator Loss: 0.001182260108180344\n",
            "Epoch 64, Generator Loss: 6.803028583526611, Discriminator Loss: 0.0011323143262416124\n",
            "Epoch 65, Generator Loss: 6.837802410125732, Discriminator Loss: 0.0010931333526968956\n",
            "Epoch 66, Generator Loss: 6.882729530334473, Discriminator Loss: 0.0010449410183355212\n",
            "Epoch 67, Generator Loss: 6.929533958435059, Discriminator Loss: 0.000997360097244382\n",
            "Epoch 68, Generator Loss: 6.965398788452148, Discriminator Loss: 0.0009618433541618288\n",
            "Epoch 69, Generator Loss: 7.007217884063721, Discriminator Loss: 0.0009222963126376271\n",
            "Epoch 70, Generator Loss: 7.049646377563477, Discriminator Loss: 0.0008840372320264578\n",
            "Epoch 71, Generator Loss: 7.085605144500732, Discriminator Loss: 0.0008524840231984854\n",
            "Epoch 72, Generator Loss: 7.124203681945801, Discriminator Loss: 0.0008203464094549417\n",
            "Epoch 73, Generator Loss: 7.155697345733643, Discriminator Loss: 0.000794764724560082\n",
            "Epoch 74, Generator Loss: 7.195502281188965, Discriminator Loss: 0.0007638653623871505\n",
            "Epoch 75, Generator Loss: 7.231328010559082, Discriminator Loss: 0.0007369730155915022\n",
            "Epoch 76, Generator Loss: 7.267056465148926, Discriminator Loss: 0.0007111081504262984\n",
            "Epoch 77, Generator Loss: 7.3036603927612305, Discriminator Loss: 0.0006855769897811115\n",
            "Epoch 78, Generator Loss: 7.346559524536133, Discriminator Loss: 0.0006568708340637386\n",
            "Epoch 79, Generator Loss: 7.371754169464111, Discriminator Loss: 0.000640351208858192\n",
            "Epoch 80, Generator Loss: 7.40583610534668, Discriminator Loss: 0.0006188664119690657\n",
            "Epoch 81, Generator Loss: 7.440604209899902, Discriminator Loss: 0.0005975806852802634\n",
            "Epoch 82, Generator Loss: 7.481424331665039, Discriminator Loss: 0.0005737814935855567\n",
            "Epoch 83, Generator Loss: 7.5139994621276855, Discriminator Loss: 0.000555235194042325\n",
            "Epoch 84, Generator Loss: 7.543385028839111, Discriminator Loss: 0.0005390410660766065\n",
            "Epoch 85, Generator Loss: 7.586814880371094, Discriminator Loss: 0.0005163204623386264\n",
            "Epoch 86, Generator Loss: 7.609661102294922, Discriminator Loss: 0.0005044560530222952\n",
            "Epoch 87, Generator Loss: 7.644479751586914, Discriminator Loss: 0.0004871907294727862\n",
            "Epoch 88, Generator Loss: 7.684435844421387, Discriminator Loss: 0.0004683004808612168\n",
            "Epoch 89, Generator Loss: 7.721792221069336, Discriminator Loss: 0.00045128166675567627\n",
            "Epoch 90, Generator Loss: 7.7459893226623535, Discriminator Loss: 0.00044038984924554825\n",
            "Epoch 91, Generator Loss: 7.782685279846191, Discriminator Loss: 0.0004246011667419225\n",
            "Epoch 92, Generator Loss: 7.804970741271973, Discriminator Loss: 0.0004151386674493551\n",
            "Epoch 93, Generator Loss: 7.848506450653076, Discriminator Loss: 0.00039763914537616074\n",
            "Epoch 94, Generator Loss: 7.861898899078369, Discriminator Loss: 0.00039208735688589513\n",
            "Epoch 95, Generator Loss: 7.902927398681641, Discriminator Loss: 0.00037645487464033067\n",
            "Epoch 96, Generator Loss: 7.930942535400391, Discriminator Loss: 0.0003660457441583276\n",
            "Epoch 97, Generator Loss: 7.957517623901367, Discriminator Loss: 0.00035632989602163434\n",
            "Epoch 98, Generator Loss: 7.99388313293457, Discriminator Loss: 0.00034358224365860224\n",
            "Epoch 99, Generator Loss: 8.021188735961914, Discriminator Loss: 0.00033428429742343724\n",
            "Epoch 100, Generator Loss: 8.051568984985352, Discriminator Loss: 0.0003242572129238397\n",
            "Generated Puzzle:\n",
            "[[5 4 2]\n",
            " [1 3 7]\n",
            " [6 0 8]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101, Generator Loss: 8.085693359375, Discriminator Loss: 0.00031341638532467186\n",
            "Epoch 102, Generator Loss: 8.10964584350586, Discriminator Loss: 0.0003059276205021888\n",
            "Epoch 103, Generator Loss: 8.138946533203125, Discriminator Loss: 0.00029710622038692236\n",
            "Epoch 104, Generator Loss: 8.169694900512695, Discriminator Loss: 0.0002881588297896087\n",
            "Epoch 105, Generator Loss: 8.191156387329102, Discriminator Loss: 0.0002819380024448037\n",
            "Epoch 106, Generator Loss: 8.226032257080078, Discriminator Loss: 0.0002723191864788532\n",
            "Epoch 107, Generator Loss: 8.262280464172363, Discriminator Loss: 0.00026270310627296567\n",
            "Epoch 108, Generator Loss: 8.277080535888672, Discriminator Loss: 0.000258721353020519\n",
            "Epoch 109, Generator Loss: 8.306526184082031, Discriminator Loss: 0.0002512221981305629\n",
            "Epoch 110, Generator Loss: 8.332623481750488, Discriminator Loss: 0.0002447469742037356\n",
            "Epoch 111, Generator Loss: 8.369613647460938, Discriminator Loss: 0.00023592566139996052\n",
            "Epoch 112, Generator Loss: 8.391901016235352, Discriminator Loss: 0.00023066558060236275\n",
            "Epoch 113, Generator Loss: 8.422550201416016, Discriminator Loss: 0.00022371055092662573\n",
            "Epoch 114, Generator Loss: 8.441350936889648, Discriminator Loss: 0.00021952245151624084\n",
            "Epoch 115, Generator Loss: 8.473775863647461, Discriminator Loss: 0.00021256475884001702\n",
            "Epoch 116, Generator Loss: 8.494510650634766, Discriminator Loss: 0.00020811115973629057\n",
            "Epoch 117, Generator Loss: 8.531787872314453, Discriminator Loss: 0.00020058419613633305\n",
            "Epoch 118, Generator Loss: 8.544784545898438, Discriminator Loss: 0.0001978723448701203\n",
            "Epoch 119, Generator Loss: 8.573667526245117, Discriminator Loss: 0.0001922709634527564\n",
            "Epoch 120, Generator Loss: 8.608301162719727, Discriminator Loss: 0.00018580493633635342\n",
            "Epoch 121, Generator Loss: 8.630434036254883, Discriminator Loss: 0.00018169940449297428\n",
            "Epoch 122, Generator Loss: 8.649774551391602, Discriminator Loss: 0.00017818760534282774\n",
            "Epoch 123, Generator Loss: 8.679364204406738, Discriminator Loss: 0.00017302113701589406\n",
            "Epoch 124, Generator Loss: 8.705899238586426, Discriminator Loss: 0.000168495302204974\n",
            "Epoch 125, Generator Loss: 8.733214378356934, Discriminator Loss: 0.00016394269187003374\n",
            "Epoch 126, Generator Loss: 8.750965118408203, Discriminator Loss: 0.00016103938105516136\n",
            "Epoch 127, Generator Loss: 8.785106658935547, Discriminator Loss: 0.00015567369700875133\n",
            "Epoch 128, Generator Loss: 8.811508178710938, Discriminator Loss: 0.00015162407362367958\n",
            "Epoch 129, Generator Loss: 8.832653045654297, Discriminator Loss: 0.0001484014792367816\n",
            "Epoch 130, Generator Loss: 8.856072425842285, Discriminator Loss: 0.00014493717753794044\n",
            "Epoch 131, Generator Loss: 8.884737014770508, Discriminator Loss: 0.00014083602582104504\n",
            "Epoch 132, Generator Loss: 8.906339645385742, Discriminator Loss: 0.00013779639266431332\n",
            "Epoch 133, Generator Loss: 8.932406425476074, Discriminator Loss: 0.0001342325413133949\n",
            "Epoch 134, Generator Loss: 8.95440673828125, Discriminator Loss: 0.00013127886631991714\n",
            "Epoch 135, Generator Loss: 8.981367111206055, Discriminator Loss: 0.00012778134259860963\n",
            "Epoch 136, Generator Loss: 9.008014678955078, Discriminator Loss: 0.00012441663420759141\n",
            "Epoch 137, Generator Loss: 9.028754234313965, Discriminator Loss: 0.00012184694787720218\n",
            "Epoch 138, Generator Loss: 9.053827285766602, Discriminator Loss: 0.0001188333990285173\n",
            "Epoch 139, Generator Loss: 9.073450088500977, Discriminator Loss: 0.000116499031719286\n",
            "Epoch 140, Generator Loss: 9.1092529296875, Discriminator Loss: 0.00011244690540479496\n",
            "Epoch 141, Generator Loss: 9.128591537475586, Discriminator Loss: 0.00011026403808500618\n",
            "Epoch 142, Generator Loss: 9.15328598022461, Discriminator Loss: 0.0001075675681931898\n",
            "Epoch 143, Generator Loss: 9.179705619812012, Discriminator Loss: 0.00010476139141246676\n",
            "Epoch 144, Generator Loss: 9.208572387695312, Discriminator Loss: 0.00010180901153944433\n",
            "Epoch 145, Generator Loss: 9.220365524291992, Discriminator Loss: 0.00010056672181235626\n",
            "Epoch 146, Generator Loss: 9.250516891479492, Discriminator Loss: 9.759808017406613e-05\n",
            "Epoch 147, Generator Loss: 9.276290893554688, Discriminator Loss: 9.51104739215225e-05\n",
            "Epoch 148, Generator Loss: 9.29353141784668, Discriminator Loss: 9.347929881187156e-05\n",
            "Epoch 149, Generator Loss: 9.316625595092773, Discriminator Loss: 9.132186096394435e-05\n",
            "Epoch 150, Generator Loss: 9.346029281616211, Discriminator Loss: 8.870469901012257e-05\n",
            "Epoch 151, Generator Loss: 9.36227035522461, Discriminator Loss: 8.72533128131181e-05\n",
            "Epoch 152, Generator Loss: 9.383380889892578, Discriminator Loss: 8.54153695399873e-05\n",
            "Epoch 153, Generator Loss: 9.403987884521484, Discriminator Loss: 8.367351983906701e-05\n",
            "Epoch 154, Generator Loss: 9.433892250061035, Discriminator Loss: 8.122560393530875e-05\n",
            "Epoch 155, Generator Loss: 9.46237850189209, Discriminator Loss: 7.895203452790156e-05\n",
            "Epoch 156, Generator Loss: 9.480264663696289, Discriminator Loss: 7.753100362606347e-05\n",
            "Epoch 157, Generator Loss: 9.495986938476562, Discriminator Loss: 7.631413609487936e-05\n",
            "Epoch 158, Generator Loss: 9.524944305419922, Discriminator Loss: 7.414856372633949e-05\n",
            "Epoch 159, Generator Loss: 9.546663284301758, Discriminator Loss: 7.255469245137647e-05\n",
            "Epoch 160, Generator Loss: 9.566195487976074, Discriminator Loss: 7.115297921700403e-05\n",
            "Epoch 161, Generator Loss: 9.592792510986328, Discriminator Loss: 6.929646770004183e-05\n",
            "Epoch 162, Generator Loss: 9.614063262939453, Discriminator Loss: 6.783393473597243e-05\n",
            "Epoch 163, Generator Loss: 9.632617950439453, Discriminator Loss: 6.657571793766692e-05\n",
            "Epoch 164, Generator Loss: 9.657905578613281, Discriminator Loss: 6.491420208476484e-05\n",
            "Epoch 165, Generator Loss: 9.679529190063477, Discriminator Loss: 6.351368210744113e-05\n",
            "Epoch 166, Generator Loss: 9.703015327453613, Discriminator Loss: 6.204445526236668e-05\n",
            "Epoch 167, Generator Loss: 9.728377342224121, Discriminator Loss: 6.050076262908988e-05\n",
            "Epoch 168, Generator Loss: 9.746545791625977, Discriminator Loss: 5.9396770666353405e-05\n",
            "Epoch 169, Generator Loss: 9.774625778198242, Discriminator Loss: 5.776372563559562e-05\n",
            "Epoch 170, Generator Loss: 9.795531272888184, Discriminator Loss: 5.657543078996241e-05\n",
            "Epoch 171, Generator Loss: 9.817407608032227, Discriminator Loss: 5.534470619750209e-05\n",
            "Epoch 172, Generator Loss: 9.837677001953125, Discriminator Loss: 5.423445691121742e-05\n",
            "Epoch 173, Generator Loss: 9.856338500976562, Discriminator Loss: 5.3227577154757455e-05\n",
            "Epoch 174, Generator Loss: 9.881404876708984, Discriminator Loss: 5.1915958465542644e-05\n",
            "Epoch 175, Generator Loss: 9.900903701782227, Discriminator Loss: 5.0910744903376326e-05\n",
            "Epoch 176, Generator Loss: 9.925567626953125, Discriminator Loss: 4.968649227521382e-05\n",
            "Epoch 177, Generator Loss: 9.943560600280762, Discriminator Loss: 4.8785503167891875e-05\n",
            "Epoch 178, Generator Loss: 9.962085723876953, Discriminator Loss: 4.788286969414912e-05\n",
            "Epoch 179, Generator Loss: 9.98725414276123, Discriminator Loss: 4.6703942643944174e-05\n",
            "Epoch 180, Generator Loss: 10.014887809753418, Discriminator Loss: 4.544578769127838e-05\n",
            "Epoch 181, Generator Loss: 10.032121658325195, Discriminator Loss: 4.466141035663895e-05\n",
            "Epoch 182, Generator Loss: 10.051825523376465, Discriminator Loss: 4.378938319860026e-05\n",
            "Epoch 183, Generator Loss: 10.07724380493164, Discriminator Loss: 4.26969381805975e-05\n",
            "Epoch 184, Generator Loss: 10.096933364868164, Discriminator Loss: 4.18614326918032e-05\n",
            "Epoch 185, Generator Loss: 10.114571571350098, Discriminator Loss: 4.112197711947374e-05\n",
            "Epoch 186, Generator Loss: 10.1397066116333, Discriminator Loss: 4.010285556432791e-05\n",
            "Epoch 187, Generator Loss: 10.165669441223145, Discriminator Loss: 3.9079488487914205e-05\n",
            "Epoch 188, Generator Loss: 10.17903995513916, Discriminator Loss: 3.8546717405552045e-05\n",
            "Epoch 189, Generator Loss: 10.20337963104248, Discriminator Loss: 3.762465712497942e-05\n",
            "Epoch 190, Generator Loss: 10.224933624267578, Discriminator Loss: 3.6814057239098474e-05\n",
            "Epoch 191, Generator Loss: 10.246108055114746, Discriminator Loss: 3.603553705033846e-05\n",
            "Epoch 192, Generator Loss: 10.269225120544434, Discriminator Loss: 3.521554754115641e-05\n",
            "Epoch 193, Generator Loss: 10.286893844604492, Discriminator Loss: 3.459118670434691e-05\n",
            "Epoch 194, Generator Loss: 10.310444831848145, Discriminator Loss: 3.378815017640591e-05\n",
            "Epoch 195, Generator Loss: 10.330375671386719, Discriminator Loss: 3.3122370950877666e-05\n",
            "Epoch 196, Generator Loss: 10.348756790161133, Discriminator Loss: 3.251303860452026e-05\n",
            "Epoch 197, Generator Loss: 10.369623184204102, Discriminator Loss: 3.184476008755155e-05\n",
            "Epoch 198, Generator Loss: 10.403985023498535, Discriminator Loss: 3.078675945289433e-05\n",
            "Epoch 199, Generator Loss: 10.408970832824707, Discriminator Loss: 3.061565075768158e-05\n",
            "Epoch 200, Generator Loss: 10.43868637084961, Discriminator Loss: 2.9734643248957582e-05\n",
            "Generated Puzzle:\n",
            "[[7 0 8]\n",
            " [2 6 4]\n",
            " [5 1 3]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201, Generator Loss: 10.45969009399414, Discriminator Loss: 2.9113747586961836e-05\n",
            "Epoch 202, Generator Loss: 10.480929374694824, Discriminator Loss: 2.8507663955679163e-05\n",
            "Epoch 203, Generator Loss: 10.500507354736328, Discriminator Loss: 2.795399268507026e-05\n",
            "Epoch 204, Generator Loss: 10.515851020812988, Discriminator Loss: 2.752473665168509e-05\n",
            "Epoch 205, Generator Loss: 10.544710159301758, Discriminator Loss: 2.6752033591037616e-05\n",
            "Epoch 206, Generator Loss: 10.560820579528809, Discriminator Loss: 2.631977440614719e-05\n",
            "Epoch 207, Generator Loss: 10.583162307739258, Discriminator Loss: 2.573906022007577e-05\n",
            "Epoch 208, Generator Loss: 10.602678298950195, Discriminator Loss: 2.524311094020959e-05\n",
            "Epoch 209, Generator Loss: 10.622820854187012, Discriminator Loss: 2.473689164617099e-05\n",
            "Epoch 210, Generator Loss: 10.641284942626953, Discriminator Loss: 2.428190600767266e-05\n",
            "Epoch 211, Generator Loss: 10.660959243774414, Discriminator Loss: 2.380781006650068e-05\n",
            "Epoch 212, Generator Loss: 10.690316200256348, Discriminator Loss: 2.312079959665425e-05\n",
            "Epoch 213, Generator Loss: 10.707494735717773, Discriminator Loss: 2.27251039177645e-05\n",
            "Epoch 214, Generator Loss: 10.724717140197754, Discriminator Loss: 2.2333890228765085e-05\n",
            "Epoch 215, Generator Loss: 10.751659393310547, Discriminator Loss: 2.1744337573181838e-05\n",
            "Epoch 216, Generator Loss: 10.775161743164062, Discriminator Loss: 2.1236372049315833e-05\n",
            "Epoch 217, Generator Loss: 10.790315628051758, Discriminator Loss: 2.091926035063807e-05\n",
            "Epoch 218, Generator Loss: 10.802482604980469, Discriminator Loss: 2.0662788301706314e-05\n",
            "Epoch 219, Generator Loss: 10.825233459472656, Discriminator Loss: 2.0196466721245088e-05\n",
            "Epoch 220, Generator Loss: 10.849327087402344, Discriminator Loss: 1.9715444068424404e-05\n",
            "Epoch 221, Generator Loss: 10.866081237792969, Discriminator Loss: 1.938789318955969e-05\n",
            "Epoch 222, Generator Loss: 10.895563125610352, Discriminator Loss: 1.883016921055969e-05\n",
            "Epoch 223, Generator Loss: 10.91026782989502, Discriminator Loss: 1.8558001102064736e-05\n",
            "Epoch 224, Generator Loss: 10.932012557983398, Discriminator Loss: 1.8154583813156933e-05\n",
            "Epoch 225, Generator Loss: 10.943928718566895, Discriminator Loss: 1.7934138668351807e-05\n",
            "Epoch 226, Generator Loss: 10.968990325927734, Discriminator Loss: 1.749013244989328e-05\n",
            "Epoch 227, Generator Loss: 10.989980697631836, Discriminator Loss: 1.7127187675214373e-05\n",
            "Epoch 228, Generator Loss: 11.015395164489746, Discriminator Loss: 1.670011261012405e-05\n",
            "Epoch 229, Generator Loss: 11.025172233581543, Discriminator Loss: 1.6531646906514652e-05\n",
            "Epoch 230, Generator Loss: 11.04991626739502, Discriminator Loss: 1.6128913557622582e-05\n",
            "Epoch 231, Generator Loss: 11.074962615966797, Discriminator Loss: 1.5733709005871788e-05\n",
            "Epoch 232, Generator Loss: 11.090099334716797, Discriminator Loss: 1.5493105820496567e-05\n",
            "Epoch 233, Generator Loss: 11.109979629516602, Discriminator Loss: 1.5189280020422302e-05\n",
            "Epoch 234, Generator Loss: 11.131607055664062, Discriminator Loss: 1.486298151576193e-05\n",
            "Epoch 235, Generator Loss: 11.152969360351562, Discriminator Loss: 1.4549916159012355e-05\n",
            "Epoch 236, Generator Loss: 11.17380142211914, Discriminator Loss: 1.4251502761908341e-05\n",
            "Epoch 237, Generator Loss: 11.19426155090332, Discriminator Loss: 1.3961322110844776e-05\n",
            "Epoch 238, Generator Loss: 11.212641716003418, Discriminator Loss: 1.3705304809263907e-05\n",
            "Epoch 239, Generator Loss: 11.232120513916016, Discriminator Loss: 1.3442097952065524e-05\n",
            "Epoch 240, Generator Loss: 11.253783226013184, Discriminator Loss: 1.3154809494153596e-05\n",
            "Epoch 241, Generator Loss: 11.276849746704102, Discriminator Loss: 1.2855438399128616e-05\n",
            "Epoch 242, Generator Loss: 11.285192489624023, Discriminator Loss: 1.274447549803881e-05\n",
            "Epoch 243, Generator Loss: 11.313885688781738, Discriminator Loss: 1.2387513379508164e-05\n",
            "Epoch 244, Generator Loss: 11.334802627563477, Discriminator Loss: 1.213109317177441e-05\n",
            "Epoch 245, Generator Loss: 11.351375579833984, Discriminator Loss: 1.1931044355151244e-05\n",
            "Epoch 246, Generator Loss: 11.367006301879883, Discriminator Loss: 1.1742846254492179e-05\n",
            "Epoch 247, Generator Loss: 11.390148162841797, Discriminator Loss: 1.1476920917630196e-05\n",
            "Epoch 248, Generator Loss: 11.409976959228516, Discriminator Loss: 1.125351082009729e-05\n",
            "Epoch 249, Generator Loss: 11.432223320007324, Discriminator Loss: 1.1006728527718224e-05\n",
            "Epoch 250, Generator Loss: 11.450920104980469, Discriminator Loss: 1.0804148587340023e-05\n",
            "Epoch 251, Generator Loss: 11.46110725402832, Discriminator Loss: 1.0691111128835473e-05\n",
            "Epoch 252, Generator Loss: 11.487136840820312, Discriminator Loss: 1.0419154932606034e-05\n",
            "Epoch 253, Generator Loss: 11.51453971862793, Discriminator Loss: 1.0141719940293115e-05\n",
            "Epoch 254, Generator Loss: 11.530826568603516, Discriminator Loss: 9.977982699638233e-06\n",
            "Epoch 255, Generator Loss: 11.54980754852295, Discriminator Loss: 9.7891852419707e-06\n",
            "Epoch 256, Generator Loss: 11.57094669342041, Discriminator Loss: 9.58476903178962e-06\n",
            "Epoch 257, Generator Loss: 11.586708068847656, Discriminator Loss: 9.435348147235345e-06\n",
            "Epoch 258, Generator Loss: 11.615921020507812, Discriminator Loss: 9.167501048068516e-06\n",
            "Epoch 259, Generator Loss: 11.626846313476562, Discriminator Loss: 9.066383427125402e-06\n",
            "Epoch 260, Generator Loss: 11.646050453186035, Discriminator Loss: 8.89423336047912e-06\n",
            "Epoch 261, Generator Loss: 11.66640853881836, Discriminator Loss: 8.714648174645845e-06\n",
            "Epoch 262, Generator Loss: 11.688658714294434, Discriminator Loss: 8.522480129613541e-06\n",
            "Epoch 263, Generator Loss: 11.708757400512695, Discriminator Loss: 8.35270020616008e-06\n",
            "Epoch 264, Generator Loss: 11.730451583862305, Discriminator Loss: 8.172678462869953e-06\n",
            "Epoch 265, Generator Loss: 11.742040634155273, Discriminator Loss: 8.075848199950997e-06\n",
            "Epoch 266, Generator Loss: 11.760160446166992, Discriminator Loss: 7.930653737275861e-06\n",
            "Epoch 267, Generator Loss: 11.786111831665039, Discriminator Loss: 7.72844759922009e-06\n",
            "Epoch 268, Generator Loss: 11.802957534790039, Discriminator Loss: 7.600393473694567e-06\n",
            "Epoch 269, Generator Loss: 11.819364547729492, Discriminator Loss: 7.475042821170064e-06\n",
            "Epoch 270, Generator Loss: 11.840522766113281, Discriminator Loss: 7.317866220546421e-06\n",
            "Epoch 271, Generator Loss: 11.854737281799316, Discriminator Loss: 7.212479431473184e-06\n",
            "Epoch 272, Generator Loss: 11.873475074768066, Discriminator Loss: 7.077718237269437e-06\n",
            "Epoch 273, Generator Loss: 11.89426040649414, Discriminator Loss: 6.931242296559503e-06\n",
            "Epoch 274, Generator Loss: 11.924583435058594, Discriminator Loss: 6.726349056407344e-06\n",
            "Epoch 275, Generator Loss: 11.940549850463867, Discriminator Loss: 6.618457518925425e-06\n",
            "Epoch 276, Generator Loss: 11.95235824584961, Discriminator Loss: 6.538410161738284e-06\n",
            "Epoch 277, Generator Loss: 11.975578308105469, Discriminator Loss: 6.387738267221721e-06\n",
            "Epoch 278, Generator Loss: 11.998598098754883, Discriminator Loss: 6.243295501917601e-06\n",
            "Epoch 279, Generator Loss: 12.016176223754883, Discriminator Loss: 6.132985163276317e-06\n",
            "Epoch 280, Generator Loss: 12.030537605285645, Discriminator Loss: 6.044267138349824e-06\n",
            "Epoch 281, Generator Loss: 12.05184555053711, Discriminator Loss: 5.916748250456294e-06\n",
            "Epoch 282, Generator Loss: 12.073230743408203, Discriminator Loss: 5.791410330857616e-06\n",
            "Epoch 283, Generator Loss: 12.093316078186035, Discriminator Loss: 5.676889941241825e-06\n",
            "Epoch 284, Generator Loss: 12.113143920898438, Discriminator Loss: 5.565197170653846e-06\n",
            "Epoch 285, Generator Loss: 12.13646125793457, Discriminator Loss: 5.438212156150257e-06\n",
            "Epoch 286, Generator Loss: 12.153520584106445, Discriminator Loss: 5.345693352865055e-06\n",
            "Epoch 287, Generator Loss: 12.167963981628418, Discriminator Loss: 5.268222139420686e-06\n",
            "Epoch 288, Generator Loss: 12.18705940246582, Discriminator Loss: 5.168141797184944e-06\n",
            "Epoch 289, Generator Loss: 12.211381912231445, Discriminator Loss: 5.044871613790747e-06\n",
            "Epoch 290, Generator Loss: 12.229701042175293, Discriminator Loss: 4.954151791025652e-06\n",
            "Epoch 291, Generator Loss: 12.244405746459961, Discriminator Loss: 4.882230768998852e-06\n",
            "Epoch 292, Generator Loss: 12.26264762878418, Discriminator Loss: 4.794437245436711e-06\n",
            "Epoch 293, Generator Loss: 12.281499862670898, Discriminator Loss: 4.706145318777999e-06\n",
            "Epoch 294, Generator Loss: 12.304573059082031, Discriminator Loss: 4.600581178237917e-06\n",
            "Epoch 295, Generator Loss: 12.33270263671875, Discriminator Loss: 4.4758889998774976e-06\n",
            "Epoch 296, Generator Loss: 12.34766674041748, Discriminator Loss: 4.408806034916779e-06\n",
            "Epoch 297, Generator Loss: 12.364044189453125, Discriminator Loss: 4.338050985097652e-06\n",
            "Epoch 298, Generator Loss: 12.381645202636719, Discriminator Loss: 4.2626579670468345e-06\n",
            "Epoch 299, Generator Loss: 12.402233123779297, Discriminator Loss: 4.176921720500104e-06\n",
            "Epoch 300, Generator Loss: 12.415543556213379, Discriminator Loss: 4.122175141674234e-06\n",
            "Generated Puzzle:\n",
            "[[0 7 8]\n",
            " [6 4 2]\n",
            " [5 3 1]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301, Generator Loss: 12.441572189331055, Discriminator Loss: 4.017569153802469e-06\n",
            "Epoch 302, Generator Loss: 12.459314346313477, Discriminator Loss: 3.945718162867706e-06\n",
            "Epoch 303, Generator Loss: 12.474961280822754, Discriminator Loss: 3.8847042560519185e-06\n",
            "Epoch 304, Generator Loss: 12.493180274963379, Discriminator Loss: 3.814421233983012e-06\n",
            "Epoch 305, Generator Loss: 12.51434326171875, Discriminator Loss: 3.7353472635004437e-06\n",
            "Epoch 306, Generator Loss: 12.528667449951172, Discriminator Loss: 3.6818817079620203e-06\n",
            "Epoch 307, Generator Loss: 12.551039695739746, Discriminator Loss: 3.6011622341902694e-06\n",
            "Epoch 308, Generator Loss: 12.575325012207031, Discriminator Loss: 3.515381877150503e-06\n",
            "Epoch 309, Generator Loss: 12.597687721252441, Discriminator Loss: 3.4388244785077404e-06\n",
            "Epoch 310, Generator Loss: 12.602252960205078, Discriminator Loss: 3.420886059757322e-06\n",
            "Epoch 311, Generator Loss: 12.628772735595703, Discriminator Loss: 3.332281949042226e-06\n",
            "Epoch 312, Generator Loss: 12.642728805541992, Discriminator Loss: 3.2862801617739024e-06\n",
            "Epoch 313, Generator Loss: 12.67181396484375, Discriminator Loss: 3.1921204026730265e-06\n",
            "Epoch 314, Generator Loss: 12.684422492980957, Discriminator Loss: 3.1520303309662268e-06\n",
            "Epoch 315, Generator Loss: 12.707344055175781, Discriminator Loss: 3.080647957176552e-06\n",
            "Epoch 316, Generator Loss: 12.718315124511719, Discriminator Loss: 3.045822495550965e-06\n",
            "Epoch 317, Generator Loss: 12.743971824645996, Discriminator Loss: 2.9695281682506902e-06\n",
            "Epoch 318, Generator Loss: 12.760194778442383, Discriminator Loss: 2.921102804975817e-06\n",
            "Epoch 319, Generator Loss: 12.7828369140625, Discriminator Loss: 2.856111677829176e-06\n",
            "Epoch 320, Generator Loss: 12.800086975097656, Discriminator Loss: 2.8067379389540292e-06\n",
            "Epoch 321, Generator Loss: 12.820686340332031, Discriminator Loss: 2.749541408775258e-06\n",
            "Epoch 322, Generator Loss: 12.839672088623047, Discriminator Loss: 2.6976106255460763e-06\n",
            "Epoch 323, Generator Loss: 12.863036155700684, Discriminator Loss: 2.6363595679868013e-06\n",
            "Epoch 324, Generator Loss: 12.882962226867676, Discriminator Loss: 2.5841327442321926e-06\n",
            "Epoch 325, Generator Loss: 12.902139663696289, Discriminator Loss: 2.534837221901398e-06\n",
            "Epoch 326, Generator Loss: 12.909025192260742, Discriminator Loss: 2.5161948542518076e-06\n",
            "Epoch 327, Generator Loss: 12.929953575134277, Discriminator Loss: 2.4645587473060004e-06\n",
            "Epoch 328, Generator Loss: 12.947244644165039, Discriminator Loss: 2.4228054371633334e-06\n",
            "Epoch 329, Generator Loss: 12.971639633178711, Discriminator Loss: 2.364680312894052e-06\n",
            "Epoch 330, Generator Loss: 12.99063491821289, Discriminator Loss: 2.320162138857995e-06\n",
            "Epoch 331, Generator Loss: 13.011019706726074, Discriminator Loss: 2.27364148486231e-06\n",
            "Epoch 332, Generator Loss: 13.02763557434082, Discriminator Loss: 2.2360684397426667e-06\n",
            "Epoch 333, Generator Loss: 13.045066833496094, Discriminator Loss: 2.1973228285787627e-06\n",
            "Epoch 334, Generator Loss: 13.073226928710938, Discriminator Loss: 2.1378277779149357e-06\n",
            "Epoch 335, Generator Loss: 13.084410667419434, Discriminator Loss: 2.1136099803698016e-06\n",
            "Epoch 336, Generator Loss: 13.105447769165039, Discriminator Loss: 2.0700031200249214e-06\n",
            "Epoch 337, Generator Loss: 13.117681503295898, Discriminator Loss: 2.0445804693736136e-06\n",
            "Epoch 338, Generator Loss: 13.146533012390137, Discriminator Loss: 1.988037865885417e-06\n",
            "Epoch 339, Generator Loss: 13.15669059753418, Discriminator Loss: 1.9670717392727965e-06\n",
            "Epoch 340, Generator Loss: 13.1795654296875, Discriminator Loss: 1.9226406493544346e-06\n",
            "Epoch 341, Generator Loss: 13.196285247802734, Discriminator Loss: 1.891162014544534e-06\n",
            "Epoch 342, Generator Loss: 13.214874267578125, Discriminator Loss: 1.85637532013061e-06\n",
            "Epoch 343, Generator Loss: 13.226715087890625, Discriminator Loss: 1.83400004516443e-06\n",
            "Epoch 344, Generator Loss: 13.24967098236084, Discriminator Loss: 1.7926428199643851e-06\n",
            "Epoch 345, Generator Loss: 13.265253067016602, Discriminator Loss: 1.7649265373620437e-06\n",
            "Epoch 346, Generator Loss: 13.28536605834961, Discriminator Loss: 1.7298996226600138e-06\n",
            "Epoch 347, Generator Loss: 13.303326606750488, Discriminator Loss: 1.6994683846860426e-06\n",
            "Epoch 348, Generator Loss: 13.321037292480469, Discriminator Loss: 1.6695555586920818e-06\n",
            "Epoch 349, Generator Loss: 13.341980934143066, Discriminator Loss: 1.6351635849787272e-06\n",
            "Epoch 350, Generator Loss: 13.363101959228516, Discriminator Loss: 1.6013747199394857e-06\n",
            "Epoch 351, Generator Loss: 13.38242244720459, Discriminator Loss: 1.570626750435622e-06\n",
            "Epoch 352, Generator Loss: 13.399011611938477, Discriminator Loss: 1.5446424868059694e-06\n",
            "Epoch 353, Generator Loss: 13.41864013671875, Discriminator Loss: 1.5146558780543273e-06\n",
            "Epoch 354, Generator Loss: 13.44448184967041, Discriminator Loss: 1.4765341802558396e-06\n",
            "Epoch 355, Generator Loss: 13.450386047363281, Discriminator Loss: 1.4667907635157462e-06\n",
            "Epoch 356, Generator Loss: 13.477951049804688, Discriminator Loss: 1.4273367696659989e-06\n",
            "Epoch 357, Generator Loss: 13.504371643066406, Discriminator Loss: 1.3903069202569895e-06\n",
            "Epoch 358, Generator Loss: 13.516592025756836, Discriminator Loss: 1.3733158539253054e-06\n",
            "Epoch 359, Generator Loss: 13.526801109313965, Discriminator Loss: 1.3594047914011753e-06\n",
            "Epoch 360, Generator Loss: 13.548681259155273, Discriminator Loss: 1.3303744026416098e-06\n",
            "Epoch 361, Generator Loss: 13.569080352783203, Discriminator Loss: 1.3041361626164871e-06\n",
            "Epoch 362, Generator Loss: 13.585744857788086, Discriminator Loss: 1.2826066040361184e-06\n",
            "Epoch 363, Generator Loss: 13.61246109008789, Discriminator Loss: 1.2490372682805173e-06\n",
            "Epoch 364, Generator Loss: 13.621309280395508, Discriminator Loss: 1.2377560096865636e-06\n",
            "Epoch 365, Generator Loss: 13.638690948486328, Discriminator Loss: 1.2164923646196257e-06\n",
            "Epoch 366, Generator Loss: 13.662134170532227, Discriminator Loss: 1.1885980484294123e-06\n",
            "Epoch 367, Generator Loss: 13.669276237487793, Discriminator Loss: 1.1799318144767312e-06\n",
            "Epoch 368, Generator Loss: 13.698476791381836, Discriminator Loss: 1.1465499483165331e-06\n",
            "Epoch 369, Generator Loss: 13.720348358154297, Discriminator Loss: 1.1221773092984222e-06\n",
            "Epoch 370, Generator Loss: 13.736626625061035, Discriminator Loss: 1.103957060877292e-06\n",
            "Epoch 371, Generator Loss: 13.749099731445312, Discriminator Loss: 1.090145588023006e-06\n",
            "Epoch 372, Generator Loss: 13.774238586425781, Discriminator Loss: 1.0635030776029453e-06\n",
            "Epoch 373, Generator Loss: 13.786432266235352, Discriminator Loss: 1.0504078318263055e-06\n",
            "Epoch 374, Generator Loss: 13.806557655334473, Discriminator Loss: 1.0298111874362803e-06\n",
            "Epoch 375, Generator Loss: 13.825075149536133, Discriminator Loss: 1.010926553135505e-06\n",
            "Epoch 376, Generator Loss: 13.853185653686523, Discriminator Loss: 9.833383955992758e-07\n",
            "Epoch 377, Generator Loss: 13.865882873535156, Discriminator Loss: 9.707382560009137e-07\n",
            "Epoch 378, Generator Loss: 13.878744125366211, Discriminator Loss: 9.58126520345104e-07\n",
            "Epoch 379, Generator Loss: 13.898368835449219, Discriminator Loss: 9.397303415425995e-07\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Constants\n",
        "PUZZLE_SIZE = 3  # 3x3 puzzle\n",
        "SEED_SIZE = 100\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Generate random 3x3 sliding puzzle configurations\n",
        "def generate_puzzle_batch(batch_size):\n",
        "    puzzles = []\n",
        "    for _ in range(batch_size):\n",
        "        puzzle = np.arange(PUZZLE_SIZE * PUZZLE_SIZE)\n",
        "        np.random.shuffle(puzzle)\n",
        "        puzzle = puzzle.reshape((PUZZLE_SIZE, PUZZLE_SIZE))\n",
        "        puzzles.append(puzzle)\n",
        "    return np.array(puzzles)\n",
        "\n",
        "# Generator\n",
        "def build_generator(seed_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=seed_size))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(PUZZLE_SIZE * PUZZLE_SIZE, activation='softmax'))  # Output is a probability distribution\n",
        "    model.add(Reshape((PUZZLE_SIZE, PUZZLE_SIZE)))\n",
        "    return model\n",
        "\n",
        "# Discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(PUZZLE_SIZE, PUZZLE_SIZE)))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(64))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Build models\n",
        "generator = build_generator(SEED_SIZE)\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "\n",
        "# Training step\n",
        "@tf.function\n",
        "def train_step(puzzles):\n",
        "    noise = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_puzzles = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(puzzles, training=True)\n",
        "        fake_output = discriminator(generated_puzzles, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for puzzle_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(puzzle_batch)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch + 1}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n",
        "\n",
        "        # Generate and save a sample puzzle\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            sample_puzzle(generator)\n",
        "\n",
        "# Function to sample a generated puzzle and plot\n",
        "def sample_puzzle(generator_model):\n",
        "    noise = tf.random.normal([1, SEED_SIZE])\n",
        "    generated_puzzle = generator_model(noise, training=False).numpy().reshape((PUZZLE_SIZE, PUZZLE_SIZE))\n",
        "\n",
        "    # Convert the generated puzzle to a valid permutation of numbers 0 to 8\n",
        "    generated_puzzle = np.argsort(generated_puzzle.flatten())  # Ensure it's a valid permutation\n",
        "    generated_puzzle = generated_puzzle.reshape((PUZZLE_SIZE, PUZZLE_SIZE))\n",
        "\n",
        "    print(\"Generated Puzzle:\")\n",
        "    print(generated_puzzle)\n",
        "\n",
        "    # Plot with labels\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    for i in range(PUZZLE_SIZE):\n",
        "        for j in range(PUZZLE_SIZE):\n",
        "            num = int(generated_puzzle[i, j])  # Convert to int to display as a number\n",
        "            color = 'lightblue' if num != 0 else 'white'  # Set color for blank space (0)\n",
        "            ax.add_patch(plt.Rectangle((j, PUZZLE_SIZE-i-1), 1, 1, facecolor=color, edgecolor='black'))\n",
        "\n",
        "            if num != 0:  # Only add number to non-zero cells\n",
        "                ax.text(j + 0.5, PUZZLE_SIZE-i-0.5, str(num), color='black', ha='center', va='center', fontsize=20)\n",
        "\n",
        "    ax.set_xlim(0, PUZZLE_SIZE)\n",
        "    ax.set_ylim(0, PUZZLE_SIZE)\n",
        "    ax.set_xticks(np.arange(0, PUZZLE_SIZE, 1))\n",
        "    ax.set_yticks(np.arange(0, PUZZLE_SIZE, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_aspect('equal')\n",
        "    plt.gca().invert_yaxis()  # To match typical 2D array coordinates where the origin is top-left\n",
        "    plt.show()\n",
        "\n",
        "# Generate dataset and train\n",
        "puzzle_data = generate_puzzle_batch(1000)\n",
        "puzzle_dataset = tf.data.Dataset.from_tensor_slices(puzzle_data).batch(BATCH_SIZE)\n",
        "\n",
        "train(puzzle_dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qoV7fs-jc00h"
      }
    }
  ]
}